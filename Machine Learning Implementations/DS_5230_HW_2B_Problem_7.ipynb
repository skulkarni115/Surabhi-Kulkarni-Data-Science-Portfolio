{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Fashion Dataset"
      ],
      "metadata": {
        "id": "sn--1wMQLMOk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXIszitwK6yJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from scipy import spatial\n",
        "from statistics import mode\n",
        "import sklearn.metrics.pairwise\n",
        "from statistics import mean\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import math\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy import spatial\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_x,train_y),(test_x, test_y) = fashion_mnist.load_data()\n",
        "new_train = []\n",
        "for i in train_x[0:40000]:\n",
        "  new_train.append(i.flatten())\n",
        "sample_train = new_train[0:4000]\n",
        "\n",
        "new_test = []\n",
        "for i in test_x[0:400]:\n",
        "  new_test.append(i.flatten())\n",
        "sample_test = new_test[0:400]"
      ],
      "metadata": {
        "id": "zG9q45mZLKws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implement distances and getting neighbors\n",
        "distances = sklearn.metrics.pairwise.euclidean_distances(sample_train,sample_train)\n",
        "#Define epsilon and min pts\n",
        "epsilon = .01\n",
        "min_pts = 100\n",
        "total_neighbors = []\n",
        "for i in range(len(sample_train)):\n",
        "  neighbors = np.argsort(distances[i])[0:(min_pts+5)]\n",
        "  counter = 0\n",
        "  for x in neighbors:\n",
        "    delete_idx = []\n",
        "    if distances[i][x] > epsilon:\n",
        "      delete_idx.append(counter)\n",
        "    counter +=1\n",
        "  neighbors = np.delete(neighbors,delete_idx)\n",
        "  total_neighbors.append(neighbors)"
      ],
      "metadata": {
        "id": "4hwoL3vXLWfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_clusters = []\n",
        "visited = []\n",
        "for i in range(4000): #len(db_dict['Xcircle_X1']\n",
        "  if i not in visited:\n",
        "    neighbors = total_neighbors[i]\n",
        "    current_cluster = []\n",
        "    queue = neighbors\n",
        "    queue = list(queue)\n",
        "    if len(neighbors) < min_pts:\n",
        "      visited.append(i)\n",
        "      continue\n",
        "    while queue:\n",
        "      num = queue.pop(0)\n",
        "      if num not in visited:\n",
        "        visited.append(num)\n",
        "        current_cluster.append(num)\n",
        "        n_neigh = total_neighbors[num]\n",
        "        if len(n_neigh)>= min_pts:\n",
        "          queue.extend(n_neigh)\n",
        "      else:\n",
        "        continue\n",
        "  else:\n",
        "    continue\n",
        "  #print(len(current_cluster))\n",
        "  all_clusters.append(current_cluster)"
      ],
      "metadata": {
        "id": "hqy7F6UkLl4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check purity here\n",
        "purity = []\n",
        "counted = []\n",
        "count = 0\n",
        "for i in range(len(all_clusters)):\n",
        "  labels = []\n",
        "  for x in all_clusters[i]:\n",
        "    label = train_y[x]\n",
        "    labels.append(label)\n",
        "  label_mode = mode(labels)\n",
        "  purity.append(labels.count(label_mode)/len(labels))\n",
        "purity_num = sum(purity)/len(all_clusters)\n",
        "print('Average Purity is ', purity_num)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1oYXiKkLm6x",
        "outputId": "a908bcf6-151f-42a2-af66-b11a8efb10ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Purity is  0.9634429104824672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20 Newsgroups"
      ],
      "metadata": {
        "id": "mRLcrlJKOIgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cate = ['alt.atheism','comp.graphics', 'misc.forsale','rec.autos','rec.sport.baseball','sci.crypt','sci.space','soc.religion.christian','talk.politics.guns','talk.politics.misc']\n",
        "\n",
        "ng_train = fetch_20newsgroups(subset='train', categories = cate )\n",
        "v = TfidfVectorizer()\n",
        "train_y = ng_train.target\n",
        "train_vector = v.fit_transform(ng_train.data)\n",
        "sample_train = train_vector[:2000]\n",
        "sample_train = csr_matrix.toarray(sample_train)"
      ],
      "metadata": {
        "id": "yyWCSCB8OMIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implement distances and getting neighbors\n",
        "distances = sklearn.metrics.pairwise.euclidean_distances(sample_train,sample_train)\n",
        "#Define epsilon and min pts\n",
        "epsilon = .1\n",
        "min_pts = 30\n",
        "total_neighbors = []\n",
        "for i in range(len(sample_train)):\n",
        "  neighbors = np.argsort(distances[i])[0:(min_pts+5)]\n",
        "  counter = 0\n",
        "  for x in neighbors:\n",
        "    delete_idx = []\n",
        "    if distances[i][x] > epsilon:\n",
        "      delete_idx.append(counter)\n",
        "    counter +=1\n",
        "  neighbors = np.delete(neighbors,delete_idx)\n",
        "  total_neighbors.append(neighbors)"
      ],
      "metadata": {
        "id": "71k5Ke8WPTw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_clusters = []\n",
        "visited = []\n",
        "for i in range(2000): #len(db_dict['Xcircle_X1']\n",
        "  if i not in visited:\n",
        "    neighbors = total_neighbors[i]\n",
        "    current_cluster = []\n",
        "    queue = neighbors\n",
        "    queue = list(queue)\n",
        "    if len(neighbors) < min_pts:\n",
        "      visited.append(i)\n",
        "      continue\n",
        "    while queue:\n",
        "      num = queue.pop(0)\n",
        "      if num not in visited:\n",
        "        visited.append(num)\n",
        "        current_cluster.append(num)\n",
        "        n_neigh = total_neighbors[num]\n",
        "        if len(n_neigh)>= min_pts:\n",
        "          queue.extend(n_neigh)\n",
        "      else:\n",
        "        continue\n",
        "  else:\n",
        "    continue\n",
        "  #print(len(current_cluster))\n",
        "  all_clusters.append(current_cluster)"
      ],
      "metadata": {
        "id": "8PwrjmMtPWCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check purity here\n",
        "purity = []\n",
        "counted = []\n",
        "count = 0\n",
        "for i in range(len(all_clusters)):\n",
        "  labels = []\n",
        "  for x in all_clusters[i]:\n",
        "    label = train_y[x]\n",
        "    labels.append(label)\n",
        "  label_mode = mode(labels)\n",
        "  purity.append(labels.count(label_mode)/len(labels))\n",
        "purity_num = sum(purity)/len(all_clusters)\n",
        "print('Average Purity is ', purity_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSWCy82NPX_e",
        "outputId": "0e9ffad2-ca9d-43c4-e056-495b50cf3751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Purity is  0.9256745433216022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#UCI Household"
      ],
      "metadata": {
        "id": "sOXFMJzJQJGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "with open('household_power_consumption.txt') as house_file:\n",
        "  all_lines = house_file.readlines()\n",
        "data = []\n",
        "date_labels = []\n",
        "for line in all_lines:\n",
        "  line = line.strip('\\n').split(';')\n",
        "  date_labels.append(line[0])\n",
        "  data.append(line[2:])\n",
        "data = data[1:] \n",
        "sample_train = []\n",
        "for i in range(4000):\n",
        "  new_row = []\n",
        "  for x in data[i]:\n",
        "    x = float(x)\n",
        "    new_row.append(x)\n",
        "  sample_train.append(new_row) "
      ],
      "metadata": {
        "id": "ah8MfG6nSTgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implement distances and getting neighbors\n",
        "distances = sklearn.metrics.pairwise.euclidean_distances(sample_train,sample_train)\n",
        "#Define epsilon and min pts\n",
        "epsilon = .001\n",
        "min_pts = 60\n",
        "#.07 and 45 gives score of .43\n",
        "total_neighbors = []\n",
        "for i in range(len(sample_train)):\n",
        "  neighbors = np.argsort(distances[i])[0:(min_pts+5)]\n",
        "  counter = 0\n",
        "  for x in neighbors:\n",
        "    delete_idx = []\n",
        "    if distances[i][x] > epsilon:\n",
        "      delete_idx.append(counter)\n",
        "    counter +=1\n",
        "  neighbors = np.delete(neighbors,delete_idx)\n",
        "  total_neighbors.append(neighbors)"
      ],
      "metadata": {
        "id": "ngdcckOZVJwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_clusters = []\n",
        "visited = []\n",
        "for i in range(4000): #len(db_dict['Xcircle_X1']\n",
        "  if i not in visited:\n",
        "    neighbors = total_neighbors[i]\n",
        "    current_cluster = []\n",
        "    queue = neighbors\n",
        "    queue = list(queue)\n",
        "    if len(neighbors) < min_pts:\n",
        "      visited.append(i)\n",
        "      continue\n",
        "    while queue:\n",
        "      num = queue.pop(0)\n",
        "      if num not in visited:\n",
        "        visited.append(num)\n",
        "        current_cluster.append(num)\n",
        "        n_neigh = total_neighbors[num]\n",
        "        if len(n_neigh)>= min_pts:\n",
        "          queue.extend(n_neigh)\n",
        "      else:\n",
        "        continue\n",
        "  else:\n",
        "    continue\n",
        "  #print(len(current_cluster))\n",
        "  all_clusters.append(current_cluster)"
      ],
      "metadata": {
        "id": "NFGyLoTUViA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Silhouette Score\n",
        "house_pred = []\n",
        "for i in range(4000):\n",
        "  for x in range(len(all_clusters)):\n",
        "    if i in all_clusters[x]:\n",
        "      house_pred.append(x)\n",
        "s_score = sklearn.metrics.silhouette_score(sample_train,house_pred)\n",
        "print('Silhouette Score is ', s_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZhb1IzGFbqs",
        "outputId": "00697ce9-1b6c-4eba-f792-c8f787f50179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score is  0.4344659829385614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check purity here\n",
        "purity = []\n",
        "counted = []\n",
        "count = 0\n",
        "for i in range(len(all_clusters)):\n",
        "  labels = []\n",
        "  for x in all_clusters[i]:\n",
        "    label = date_labels[x]\n",
        "    labels.append(label)\n",
        "  label_mode = mode(labels)\n",
        "  purity.append(labels.count(label_mode)/len(labels))\n",
        "purity_num = sum(purity)/len(all_clusters)\n",
        "print('Average Purity is ', purity_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7EHCQ7hVm-Y",
        "outputId": "c9fc866a-79a1-4bea-b716-53a4ce87d84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Purity is  0.6800900450225112\n"
          ]
        }
      ]
    }
  ]
}